{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkD04wrMOVyo"
   },
   "source": [
    "# Statistical NLP Project - 1\n",
    "## Author: Sridharan Chandran "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCzL46wb7lST"
   },
   "source": [
    "## PART - A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zovpRTk9zNLU"
   },
   "source": [
    "* **DOMAIN:** Digital content management.\n",
    "\n",
    "* **CONTEXT:** Classification is probably the most popular task that you would deal with in real life. Text in the form of blogs, posts, articles, etc.are written every second. It is a challenge to predict the information about the writer without knowing about him/her. We are going to create a\n",
    "classifier that predicts multiple features of the author of a given text. We have designed it as a Multi label classification problem.\n",
    "\n",
    "* **DATA DESCRIPTION:** Over 600,000 posts from more than 19 thousand bloggers The Blog Authorship Corpus consists of the collected posts of\n",
    "19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or\n",
    "approximately 35 posts and 7250 words per person. Each blog is presented as a separate file, the name of which indicates a blogger id# and\n",
    "the blogger’s self-provided gender, age, industry, and astrological sign. (All are labelled for gender and age but for many, industry and/or sign is\n",
    "marked as unknown.) All bloggers included in the corpus fall into one of three age groups:\n",
    "• 8240 \"10s\" blogs (ages 13-17),\n",
    "• 8086 \"20s\" blogs(ages 23-27) and\n",
    "• 2994 \"30s\" blogs (ages 33-47)\n",
    "• For each age group, there is an equal number of male and female bloggers. Each blog in the corpus includes at least 200 occurrences of\n",
    "common English words. All formatting has been stripped with two exceptions. Individual posts within a single blogger are separated by the\n",
    "date of the following post and links within a post are denoted by the label url link.\n",
    "\n",
    "* **PROJECT OBJECTIVE:** To build a NLP classifier which can use input text parameters to determine the label/s of the blog. Specific to this case\n",
    "study, you can consider the text of the blog: ‘text’ feature as independent variable and ‘topic’ as dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyvBq5WozNgf"
   },
   "source": [
    "## Steps and tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wLis49-j1PVm"
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, hamming_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imwnttaczNwW"
   },
   "source": [
    "## 1. Read and Analyse Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gR33bR6D04ho"
   },
   "source": [
    "### A. Clearly write outcome of data analysis(Minimum 2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUYlsHBX130A",
    "outputId": "55725c46-a919-42f7-9374-a22079d36c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gQ9Q1a9U2djs"
   },
   "outputs": [],
   "source": [
    "# Extract the ZIP file\n",
    "file_path = \"/content/drive/My Drive/Colab Notebooks/My Python Projects/Statistical NLP Project - 1/blogs.zip\"\n",
    "\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(file_path,'r') as zip:\n",
    "  zip.extractall(path='/content/drive/My Drive/Colab Notebooks/My Python Projects/Statistical NLP Project - 1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "5oy-pScK3PtP",
    "outputId": "7cf5b427-0260-4132-ad38-a10a135a8e39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4504d434-fb2d-4e8b-aaa3-9e47955fa543\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4504d434-fb2d-4e8b-aaa3-9e47955fa543')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4504d434-fb2d-4e8b-aaa3-9e47955fa543 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4504d434-fb2d-4e8b-aaa3-9e47955fa543');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/My Python Projects/Statistical NLP Project - 1/blogtext.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lP3vRvf35XDE",
    "outputId": "ad5b3584-b4bd-4da4-b215-8c9ea69a35c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681284, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # Shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKI3suoU50og",
    "outputId": "38d360c9-c2af-4e84-e220-4e25f44350bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19320"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"id\"].nunique() # No. of bloggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1w8zH2e6KkS",
    "outputId": "e7e666ce-ac98-43ab-9b52-be2ce09aba9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'gender', 'age', 'topic', 'sign', 'date', 'text'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # Features Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sq2dBXHS6gJI",
    "outputId": "8f0e97a2-fa6d-4e61-8db7-15b585aa6c18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for id:\n",
      "449628     4221\n",
      "734562     2301\n",
      "589736     2294\n",
      "1975546    2261\n",
      "958176     2244\n",
      "           ... \n",
      "3424020       1\n",
      "4325089       1\n",
      "3516939       1\n",
      "3331848       1\n",
      "3717818       1\n",
      "Name: id, Length: 19320, dtype: int64\n",
      "================================================\n",
      "Value counts for gender:\n",
      "male      345193\n",
      "female    336091\n",
      "Name: gender, dtype: int64\n",
      "================================================\n",
      "Value counts for age:\n",
      "17    80859\n",
      "24    80071\n",
      "23    72889\n",
      "16    72708\n",
      "25    67051\n",
      "26    55312\n",
      "27    46124\n",
      "15    41767\n",
      "14    27400\n",
      "34    21347\n",
      "33    17584\n",
      "35    17462\n",
      "36    14229\n",
      "13    13133\n",
      "37     9317\n",
      "38     7545\n",
      "39     5556\n",
      "40     5016\n",
      "45     4482\n",
      "43     4230\n",
      "41     3738\n",
      "48     3572\n",
      "42     2908\n",
      "46     2733\n",
      "47     2207\n",
      "44     2044\n",
      "Name: age, dtype: int64\n",
      "================================================\n",
      "Value counts for topic:\n",
      "indUnk                     251015\n",
      "Student                    153903\n",
      "Technology                  42055\n",
      "Arts                        32449\n",
      "Education                   29633\n",
      "Communications-Media        20140\n",
      "Internet                    16006\n",
      "Non-Profit                  14700\n",
      "Engineering                 11653\n",
      "Law                          9040\n",
      "Publishing                   7753\n",
      "Science                      7269\n",
      "Government                   6907\n",
      "Consulting                   5862\n",
      "Religion                     5235\n",
      "Fashion                      4851\n",
      "Marketing                    4769\n",
      "Advertising                  4676\n",
      "BusinessServices             4500\n",
      "Banking                      4049\n",
      "Chemicals                    3928\n",
      "Telecommunications           3891\n",
      "Accounting                   3832\n",
      "Military                     3128\n",
      "Museums-Libraries            3096\n",
      "Sports-Recreation            3038\n",
      "HumanResources               3010\n",
      "RealEstate                   2870\n",
      "Transportation               2326\n",
      "Manufacturing                2272\n",
      "Biotech                      2234\n",
      "Tourism                      1942\n",
      "LawEnforcement-Security      1878\n",
      "Architecture                 1638\n",
      "InvestmentBanking            1292\n",
      "Automotive                   1244\n",
      "Agriculture                  1235\n",
      "Construction                 1093\n",
      "Environment                   592\n",
      "Maritime                      280\n",
      "Name: topic, dtype: int64\n",
      "================================================\n",
      "Value counts for sign:\n",
      "Cancer         65048\n",
      "Aries          64979\n",
      "Taurus         62561\n",
      "Libra          62363\n",
      "Virgo          60399\n",
      "Scorpio        57161\n",
      "Pisces         54053\n",
      "Leo            53811\n",
      "Gemini         51985\n",
      "Sagittarius    50036\n",
      "Aquarius       49687\n",
      "Capricorn      49201\n",
      "Name: sign, dtype: int64\n",
      "================================================\n",
      "Value counts for date:\n",
      "02,August,2004     16544\n",
      "01,August,2004     13261\n",
      "03,August,2004     11851\n",
      "05,August,2004      9297\n",
      "04,August,2004      8661\n",
      "                   ...  \n",
      "10,Januar,2004         1\n",
      "02,enero,2004          1\n",
      "15,Mai,2004            1\n",
      "08,enero,2004          1\n",
      "21,October,2000        1\n",
      "Name: date, Length: 2616, dtype: int64\n",
      "================================================\n",
      "Value counts for text:\n",
      "         urlLink                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         445\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         395\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         338\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         310\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         271\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ... \n",
      "             Friday.  Left work at 1pm, but wasted the afternoon catching up on the sleep I had been skipping.  Mr. Red and I left the apartment sober.  An odd thing, and left to meet Miss M. to see !!! at the Bowery.  They completely cemented my idea that they are the best live band in NYC (recorded, its an entirely different story).  Sorry Franz, but you have nothing on !!! when it comes to getting a crowd to dance.  Abso-fucking-lutely nothing.  Maybe it was the Vodka chugged at Miss M.'s right before the show.  Maybe it was the uppers.  But I felt like it was my fucking birthday.  I was happy and relaxed, smiling and playing with strangers.  After the show, went to a bar to see friends DJ and celebrated birthdays.  Still all smiles and happiness and spent most of the evening kissing a girl with a very pleasant disposition.  Eventually, at about 6:00 am, I found myself walking home in the morning sun, still twirling and jumping.  Saturday.  Slept in late.  Missed the beautiful day.  Watched a movie.  Sat there contented, and thought that I might not NEED to go out.  I told Alex that I was actually happy and had no desire to bury my problems with alcohol.  He said, 'Oh, no, that's not good at all.'  And so eventually, I left the house, sober, again.  Wow, two nights in a row.  and met up with Mr. Red and barhopped briefly before Mr. Red, who had been drinking continuously for about 15 hours, decided it was time to call it a night.  I met up with Alex and some of his friends, and we spent the night dancing away with good people.  At 4:30 in the morning, I started the journey back to the subway.  I witnessed two men attempting to rob a pizza place, with fake guns that were so obviously their fingers in their pockets that despite their yelling, were completely ignored by the owners and patrons.  Down the block a flock of Frat boys were harassing some poor drunk girl where I heard the wonderful piece of reasoning, 'and then her skirt blew up and I saw she was wearing a skimpy thong and I just KNEW she was good at numerous sexual acts.'  Yes boys.  Thanks for showing the ladies how deep we are.  Then the sweetest gay man in the world tried to hit on me in a deli and it nearly broke my heart to tell him I wouldn't go home with him.  He was such an angel.  The subway ride home was fun, as I twirled, swung, and hung upside down on the bars as the traine rushed under the river back to Brooklyn.  Some young girl, maybe 18?, wearing a cute flowing yellow skirt smiled and jumped up on the bars and asked me to spot her and she showed me her gymnastic skills.  We hung and swung laughing together as a man near by threw up.  I left the subway station and found myself in the morning sun again.  I stopped and lit a candle at the shrine for Frank, a local neighborhood fixture who died recently.  Walking home in the morning sun usually depresses me, but I found it quite pleasant.  I think this summer may be ok after all.               1\n",
      "             After missing the sun on Saturday, I decided that no day was better for catching the sun than Sunday.  The weather was perfect.  It was like living inside yourself.  You couldn't feel the air.  It was not hot, it was not cold.  It just was.  The boundry between the body and the world disappeared.  I walked around the city and my mood was still glowing.  Not even the massive crowds on Broadway could get me down.  I walked, laughing, as I meandered my way through the gluttony of shoppers.  Eventually, I ended up in Soho, sitting on a stoop, waiting for a couple friends.  I people watched.  Then it hit me.  That despite the plethora of short skirts and tank tops, I was not lusting after a single body.  my sex drive was non-existent.  No dirty thoughts, no ideas of crude sex.  Nothing.  Was this the reason why I had been so happy?  Was Buddha right?  The way to peace is the escape from desire?  Why do I even want a woman in my life?  Is love a fallacy to help me just procreate?  Is it just about continuing the species?  Do I want to do that?  Do I really want to bring in another life into this world to contemplate, life, death, mortality, morality, longing, failure, purpose, God?  I shrugged it all off and enjoyed the company of friends, sipping cool drinks, walking breezily through the city.  The streets that had been boring recently all of a sudden felt comforting.  The avenues greeted me like family and I wandered freely, knowing every block that was to come.  Smiling at it and giving it a proper 'good afternoon' nod.  Friends were everywhere.  I saw people, stopped talked, caught up, then went on.    I felt loved by both man and machine, by birds and buildings.  Simply, by all that was. It was such a comforting afternoon.   At one point, I stopped into Crif dog to get a hot dog (the only substantial warm meal I could afford with the $2 in my pocket).  Inside there was a girl.  She had one of those faces that makes you glow.  The kind where you know you would never tire of it.  And you know that you'd wake up happy every morning that you woke up with that face on the pillow next to you.  But longing still escaped me and I just stood there, smiling, appreciating the peacefulness burried in that smile.  I blinked my eyes like a shutter and captured it forever in my head and went on my way.  As Ice Cube said, 'Today was a good day.'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1\n",
      "             The wonderful mood of the weekend has passed.  Maybe its the grey skies and rain, but more likely, its because Elle emailed me asking a favor.  Not a favor for her, but her boyfriend.  You can ask me to stop communicating with you because you want to smooth things over with your boyfriend, but, for Christ's sake, I'm not going to do the man whom you stopped talking to me over any favors.  I'm sorry.  I'm too immature for that shit.  Now I am pissed.  Former lovers can ruin such good moods.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
      "             I am super busy at work.  No time for a real post.  So random thought.  I watched Rosemary's Baby last night for the first time.  God, that 23 year old Mia Farrow looks eerily like my ex-girlfriend.  I mean, strikingly.  I went to look  up her photos on Friendster and show someone who was watching the movie with me.  She had de-friended me.  I guess because I had sex with her roommate a couple weeks back.  I guess thats fair.  In concept, one should not have sex with an ex's roommate.  But what about if you only dated for a month?  What about if it was years ago?  What about if they ended things coldly with you?  Part of me thinks that by her dumping me harshly, she gave me a free pass to break some of those courtesy rules, such as, 'Don't fuck the roommate.'  But even if she didn't.  What is the statute of limitations on such obligations to an ex?  I mean, she has a new boyfriend and is in love, plus this roommate was not her roommate back then.  Hell, they didn't even become friends until a year after the breakup.  The roommate never even knew us as a couple.  I heard my ex was so pissed at her roommate, she moved out.  Oh, and if you're curious, the roommate was the one I 'girled' too much and is thus weirded out and doesn't really talk to me.  So, now I don't talk to either one.  One night of sex cost me two friends.  Fuck.  Thats much more than any whore would charge.  And I really actually like them both a lot.  They are both good people.  Now I remember why I abstained from sex for six months.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1\n",
      "                 I want to consider myself a rawfoodist.  Yes, I like to make it one word.  I love the whole concept.  I feel I have the gist of it down, but I'm still reading everything I can get my hands on about the subject.  Can changing one's diet like this really change the person?  I want to change.  I haven't been too thrilled with myself lately.  After 3 kids, my weight is up there and I look and feel like hell.  I started adding more and more raw food into my life a couple of weeks ago, but this week is my true beginning.  I am in love with the idea of natural hygiene and living the way I know we're supposed to.   I'm in what they call a 'transitional' phase right now.  I am eating a few complicated meals trying to get the taste and feel of cooked crappy food.   But I do appreciate the simple, mono foods as well.  I think I'm at around 75% raw at the moment with the expectation of getting to 95% in the near future.  The fun part of this whole thing is that I'm tasting new things such as young coconut, dates, and berries that are fresh and organic and not smushed little pathetic plastic-y things found in frozen pancakes.   Let me tell you what I ate today.  I started the morning with coffee.  Ok, I'm down to one cup one or two mornings a week.  Not bad for someone who relied on that thrice daily caffeine jolt just to get some housework done.  Lets pretend I didn't have that.  Anyway, I ate a banana and drove with everyone out to my mom's.  Bill (hubby dearest) took off today to spend some family time.  I actually brought a huge bage of food and my old juicer.   We stopped off at 7-11 where the kids all got a free slurpee (and Bill too)  and I got a great looking, huge salad for $3.99.  At mom's I cut up a nice mango and threw it in the salad (instead of dressing).  That was actually really yummy.  I never thought mango and onions would taste ok together (then Bill reminded me that Bobby Flay made mango salsa once).   Later on I juiced a bunch of carrots with a bit of apple - Kait (10) had some, too.  She loves fresh juice - and makes killer smoothies.  At dinnertime Dad ordered out pizza and salad.  So I had one slice of pizza with a giant sized plate of salad.  Hey, I'm not perfect.  I ended the night with one glass of zinfandel and totalled about 5 cigarettes for the day.  I am quitting this vile habit on my 35th birthday which is in exactly 22 days.   Most days are like this - last week was worse - next week will be better.  I really do love eating raw.  I have a bit of a hard time with peer pressure/will power/power of suggestion - call it what you want.  I'm overcoming that as well.   Here are the current stats:  Weight: 185.5  (I'm 5'4', so this sucks) Bust:  40' Waist:  37' Hips:  43' Upper Arm:  14' Thigh:  22'                                                                                                                                                                                                  1\n",
      "Name: text, Length: 611652, dtype: int64\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "  print(f\"Value counts for {col}:\")\n",
    "  print(df[col].value_counts())\n",
    "  print(\"================================================\") # Check for value counts of each Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xy8gaW5_4SYY"
   },
   "source": [
    "## Observations:\n",
    "\n",
    "* **Dataset:** The dataset consists of 681,284 posts written by 19,320 bloggers. Each blog is presented as a separate file and contains information about the blogger's gender, age, industry, and astrological sign (although some of these attributes may be marked as unknown).\n",
    "\n",
    "* **Multi-label Classification:** The task is framed as a multi-label classification problem, where the goal is to predict multiple features of the author based on the given text. The specific features to be predicted are not mentioned, but it can be inferred that at least the gender, age, industry, and astrological sign are among the potential labels.\n",
    "\n",
    "* **Age Groups:** The bloggers in the corpus are categorized into three age groups: \"10s\" (ages 13-17), \"20s\" (ages 23-27), and \"30s\" (ages 33-47). Each age group has an equal number of male and female bloggers.\n",
    "\n",
    "* **Textual Features:** The main independent variable for the classification task is the text of the blog itself. The dataset mentions that each blog includes at least 200 occurrences of common English words. The formatting has been stripped from the text, except for the separation of individual posts by the date of the following post and the presence of URL links.\n",
    "\n",
    "* **Label Imbalance:** The data description doesn't explicitly mention the distribution of labels or the presence of any class imbalance issues. However, it states that for many bloggers, the industry and astrological sign attributes are marked as unknown, which suggests that there might be missing or incomplete label information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ECdKqbM5Wd4"
   },
   "source": [
    "## B. Clean the Structured Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ohxy7YPMA_uR"
   },
   "source": [
    "### (i). Missing value analysis and imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJqEo_a3-sUP",
    "outputId": "3e9e2608-74c2-4dc2-8021-99d5790e987f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "gender    0\n",
       "age       0\n",
       "topic     0\n",
       "sign      0\n",
       "date      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00dDzZf_BLdK"
   },
   "source": [
    "**There is no null value in the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Ysv6Z-m-7tk",
    "outputId": "e21a80e1-2369-41ac-88e3-e41f733081c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4686"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum() # Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJBQ76EC_LRf",
    "outputId": "339a061d-6929-4b9b-f967-c76dd70b7e39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(676598, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(keep='first',inplace=True) # Drop the duplicate values\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KV5m9BAR_moc",
    "outputId": "0e17d09b-565f-47b9-90c3-617af3fc34a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 676598 entries, 0 to 681283\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   id      676598 non-null  int64 \n",
      " 1   gender  676598 non-null  object\n",
      " 2   age     676598 non-null  int64 \n",
      " 3   topic   676598 non-null  object\n",
      " 4   sign    676598 non-null  object\n",
      " 5   date    676598 non-null  object\n",
      " 6   text    676598 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 41.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "4J62nBGEAL3U",
    "outputId": "1fa64cc7-9862-4708-f704-fab0dae384d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4497e124-cb73-45d9-8c98-11af0115a992\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>676598.0</td>\n",
       "      <td>2.395488e+06</td>\n",
       "      <td>1.248401e+06</td>\n",
       "      <td>5114.0</td>\n",
       "      <td>1236636.0</td>\n",
       "      <td>2596124.0</td>\n",
       "      <td>3526127.0</td>\n",
       "      <td>4337650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>676598.0</td>\n",
       "      <td>2.393915e+01</td>\n",
       "      <td>7.774925e+00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4497e124-cb73-45d9-8c98-11af0115a992')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4497e124-cb73-45d9-8c98-11af0115a992 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4497e124-cb73-45d9-8c98-11af0115a992');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        count          mean           std     min        25%        50%  \\\n",
       "id   676598.0  2.395488e+06  1.248401e+06  5114.0  1236636.0  2596124.0   \n",
       "age  676598.0  2.393915e+01  7.774925e+00    13.0       17.0       24.0   \n",
       "\n",
       "           75%        max  \n",
       "id   3526127.0  4337650.0  \n",
       "age       26.0       48.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T # 5 point summery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrKJf18eAVrW"
   },
   "source": [
    "### (ii). Eliminate Non-English textual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rYg7WYlDzg9k"
   },
   "outputs": [],
   "source": [
    "# Take 30000 sample data from whole dataset\n",
    "df1 = df.sample(n=30000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9FYLC4bDCkBn",
    "outputId": "be6ee751-dd43-4dd1-da72-bc79fe1e05f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=6b1dacb5f4ea0fb648784046610870e3308abfa775af22db46ddbf1f1bf345d6\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jU-DI0xIBj-W"
   },
   "outputs": [],
   "source": [
    "from langdetect import detect # Language detection\n",
    "\n",
    "def is_english(text):\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        return lang == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "df1['is_english'] = df1['text'].apply(lambda x: is_english(x))\n",
    "\n",
    "df1 = df1[df1['is_english']]\n",
    "df1.drop(columns=['is_english'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "alCmgQqfHr24",
    "outputId": "507f05d0-8933-4478-ba0b-24a9e74e21d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28747, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8j3iCRCTXaRU"
   },
   "source": [
    "## 2. Preprocess unstructured data to make it consumable for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyuGzjoXXhpI"
   },
   "source": [
    "### A. Eliminate All special Characters and Numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "TOLbgpKhYOsp"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    \"\"\"\n",
    "    Removes all special characters and numbers from the given text\n",
    "    \"\"\"\n",
    "    # Replace all non-alphabetic characters with space\n",
    "    text = re.sub('[^A-Za-z]+', ' ', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jGFuwOKMYTsn"
   },
   "outputs": [],
   "source": [
    "# Apply remove_special_chars() function to 'text' column of our dataset\n",
    "df1['text'] = df1['text'].apply(remove_special_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-YZkkLiqYd5f",
    "outputId": "e9352640-7aa4-4d63-9a62-5faacdc50f47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255678     ahhh hayo i dunt believe we are in yr carazy ...\n",
       "606383     For the first time since the end of school I ...\n",
       "40902      Wow today has been HECTIC to say the least We...\n",
       "626648     Celebrating posts of Jonah Hosted by Laurence...\n",
       "71623      Man I ve been having some majorly trippy drea...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMNgOnD0Xo-U"
   },
   "source": [
    "### B. Lowercase all textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3utsMU5IY0dv"
   },
   "outputs": [],
   "source": [
    "df1['text'] = df1['text'].apply(lambda x: x.lower()) # Convert the words to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd1BIu1BZDni",
    "outputId": "a395a5aa-7148-488b-8204-cbdd342bfc2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255678     ahhh hayo i dunt believe we are in yr carazy ...\n",
       "606383     for the first time since the end of school i ...\n",
       "40902      wow today has been hectic to say the least we...\n",
       "626648     celebrating posts of jonah hosted by laurence...\n",
       "71623      man i ve been having some majorly trippy drea...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIk4lkycXvPa"
   },
   "source": [
    "### C. Remove all Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DtbzgYXEZ2g3",
    "outputId": "b126c028-f648-4e76-84c2-d6ec4aea04d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WI0x4ttkZ1v5"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in stop_words]\n",
    "    return \" \".join(text)\n",
    "    \n",
    "df1['text'] = df1['text'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TP0L_ojX0QV"
   },
   "source": [
    "### D. Remove all extra white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1D79kV4BbKbO",
    "outputId": "2184eb4e-24c7-42b2-d74d-5bb4ef5b1877"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255678    ahhh hayo dunt believe yr carazy yes well weir...\n",
       "606383    first time since end school met brandon sean p...\n",
       "40902     wow today hectic say least busy year hope sign...\n",
       "626648    celebrating posts jonah hosted laurence fishbu...\n",
       "71623     man majorly trippy dreams past week two last n...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove extra white spaces\n",
    "df1['text'] = df1['text'].apply(lambda x: re.sub('\\s+', ' ', x).strip())\n",
    "\n",
    "df1['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFGBi0TabrKT"
   },
   "source": [
    "## 3. Build a base Classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GegVDWybxJM"
   },
   "source": [
    "### A. Create dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "F4SpKizK0vpn"
   },
   "outputs": [],
   "source": [
    "X = df1['text'] # Independent variables \n",
    "y = df1['topic'] # Dependent variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEXdAunqb0xp"
   },
   "source": [
    "### B. Split data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SnArPVkvAPZk",
    "outputId": "b99ad8e7-513f-4457-ed7e-2f33f8aab81b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is (20122,)\n",
      "X_test shape is (8625,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42) # Taken 30% of the data for testing\n",
    "\n",
    "print(\"X_train shape is\", X_train.shape)\n",
    "print(\"X_test shape is\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfRfYdlib9h2"
   },
   "source": [
    "### C. Vectorize data using any one vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jFAShhX89V76",
    "outputId": "4a21ade1-f86d-4627-fa8c-576a306bf416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Ti94suGsA_4n"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vectorize data using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "BzRjjmSL9n2P"
   },
   "outputs": [],
   "source": [
    "X_train_vec = vectorizer.fit_transform(X_train) # Train vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ihCQNecq9yWk"
   },
   "outputs": [],
   "source": [
    "X_test_vec = vectorizer.transform(X_test) # Test vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOBq7iOvcBiz"
   },
   "source": [
    "### D. Build a base model for Supervised Learning - Classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "y6tI5sZ8WWF8"
   },
   "outputs": [],
   "source": [
    "#Import Naive bayes algorithm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Naive Bayes\n",
    "nb_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "WaLIEAe1QIJx",
    "outputId": "ccbc0d1f-38c3-435c-c424-394f18d45d4b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Naive bayes model\n",
    "\n",
    "nb_model.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvoESvsXcFoC"
   },
   "source": [
    "### E. Clearly print Performance Metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQzgSy3tB1Cb",
    "outputId": "5fd833f6-c445-46c0-e790-031f8caea5f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3705507246376812\n",
      "Precision: 0.3705507246376812\n",
      "Recall: 0.3705507246376812\n",
      "F1-score: 0.3705507246376812\n",
      "Hamming Loss: 0.6294492753623189\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = nb_model.predict(X_test_vec)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='micro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='micro'))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred, average='micro'))\n",
    "print(\"Hamming Loss:\", hamming_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05ouWjxiEWZT"
   },
   "source": [
    "##4. Improve Performance of model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEwo0b4fEcsx"
   },
   "source": [
    "### A. Experiment with other vectorisers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "uMGem1uSJPBr"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDDH88y05dvB",
    "outputId": "a7cd0fc4-82e0-4ed1-deaa-c122dc3d468a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20122, 86364)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBmkATamVwRb",
    "outputId": "1ed23afa-59e1-4fcd-8bd4-9687ca18239d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8625, 86364)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EByUHelwEiNQ"
   },
   "source": [
    "\n",
    "### B. Build classifier Models using other algorithms than base model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "xJFTeGvgJi9L"
   },
   "outputs": [],
   "source": [
    "#Import RandomForest algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "eLmqZasyiZqX",
    "outputId": "940d978e-086b-48be-b533-a39acccc50b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Random Forest model on the current batch\n",
    "rf_model.fit(X_train_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "hPRVo_wSP3IV",
    "outputId": "22c31503-2d57-487a-ce04-30451531a569"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create and train the SVM classifier\n",
    "svm_model = SVC()\n",
    "\n",
    "svm_model.fit(X_train_count, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txzFFN9-EoIJ"
   },
   "source": [
    "### C. Tune Parameters/Hyperparameters of the model/s. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwrkCfhnEr4s"
   },
   "source": [
    "### D. Clearly print Performance Metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "E6uyLHc3n8H7"
   },
   "outputs": [],
   "source": [
    "# Random search for parameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "ID0wSx4koBuy"
   },
   "outputs": [],
   "source": [
    "# Perform randomized search\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf_model,\n",
    "    param_distributions=param_grid,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "_N044UztoGN6",
    "outputId": "66ae1916-409f-4002-8850-1c177391388d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [5, 10, 15],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [5, 10, 15],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'max_depth': [5, 10, 15],\n",
       "                                        'n_estimators': [100, 200, 300]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on the training set\n",
    "random_search.fit(X_train_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "xnlocb3ZJ-04"
   },
   "outputs": [],
   "source": [
    "# Get the best model after parameter tuning\n",
    "best_rf_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mSM8QqkNuo7Q",
    "outputId": "5f477ace-d0ae-4b2c-f33e-3dbd1d703fcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Accuracy: 0.3770434782608696\n",
      "Precision: 0.3770434782608696\n",
      "Recall: 0.3770434782608696\n",
      "F1-score: 0.3770434782608696\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf_model.predict(X_test_count)\n",
    "\n",
    "# RandomForest Metrics\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf, average='micro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf, average='micro'))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_rf, average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1LgUxAzF38Z",
    "outputId": "9d74df4b-41cd-4a87-d509-b958d8e0efdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Metrics:\n",
      "Accuracy: 0.38168115942028985\n",
      "Precision: 0.38168115942028985\n",
      "Recall: 0.38168115942028985\n",
      "F1-score: 0.38168115942028985\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = svm_model.predict(X_test_count)\n",
    "\n",
    "# SVM Classifier Metrics\n",
    "print(\"SVM Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm, average='micro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm, average='micro'))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_svm, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a6ssHVPKV9S",
    "outputId": "80d24180-30cf-462a-ba0b-d0e76a735ae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned RandomForest Metrics:\n",
      "Accuracy: 0.368463768115942\n",
      "Precision: 0.368463768115942\n",
      "Recall: 0.368463768115942\n",
      "F1-score: 0.36846376811594206\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf_cv = best_rf_model.predict(X_test_count)\n",
    "\n",
    "# Tuned RandomForest Metrics\n",
    "print(\"Tuned RandomForest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf_cv))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf_cv, average='micro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf_cv, average='micro'))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred_rf_cv, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4HhNS4W-8yW",
    "outputId": "457ff368-1207-4b16-e49a-610063698ee9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6542"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear backend session\n",
    "from keras import backend as K\n",
    "import gc\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92u1Ry-T1kaz"
   },
   "source": [
    "**Let's  try with Deep Learning Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qyU13n-U4Ueh",
    "outputId": "915da473-dad6-49d8-9b1e-36503a4734a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "719/719 [==============================] - 247s 339ms/step - loss: 2.3874 - accuracy: 0.3617 - val_loss: 2.4034 - val_accuracy: 0.3663\n",
      "Epoch 2/10\n",
      "719/719 [==============================] - 242s 336ms/step - loss: 2.3212 - accuracy: 0.3707 - val_loss: 2.3008 - val_accuracy: 0.3663\n",
      "Epoch 3/10\n",
      "719/719 [==============================] - 224s 311ms/step - loss: 2.3033 - accuracy: 0.3710 - val_loss: 2.3083 - val_accuracy: 0.3663\n",
      "Epoch 4/10\n",
      "719/719 [==============================] - 243s 338ms/step - loss: 2.2768 - accuracy: 0.3711 - val_loss: 2.3325 - val_accuracy: 0.3663\n",
      "Epoch 5/10\n",
      "719/719 [==============================] - 243s 338ms/step - loss: 2.2656 - accuracy: 0.3711 - val_loss: 2.3285 - val_accuracy: 0.3663\n",
      "Epoch 6/10\n",
      "719/719 [==============================] - 244s 339ms/step - loss: 2.2536 - accuracy: 0.3710 - val_loss: 2.3301 - val_accuracy: 0.3609\n",
      "Epoch 7/10\n",
      "719/719 [==============================] - 242s 337ms/step - loss: 2.2497 - accuracy: 0.3698 - val_loss: 2.3160 - val_accuracy: 0.3663\n",
      "Epoch 8/10\n",
      "719/719 [==============================] - 243s 338ms/step - loss: 2.2475 - accuracy: 0.3703 - val_loss: 2.3144 - val_accuracy: 0.3638\n",
      "Epoch 9/10\n",
      "719/719 [==============================] - 242s 337ms/step - loss: 2.2438 - accuracy: 0.3699 - val_loss: 2.3408 - val_accuracy: 0.3663\n",
      "Epoch 10/10\n",
      "719/719 [==============================] - 223s 310ms/step - loss: 2.2436 - accuracy: 0.3717 - val_loss: 2.3357 - val_accuracy: 0.3663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9f9349a620>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import optimizers\n",
    "\n",
    "# Preprocess the labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(y)\n",
    "\n",
    "# Tokenize the texts\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Pad sequences to the same length\n",
    "max_sequence_length = max([len(seq) for seq in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))  # Add dropout regularization\n",
    "model.add(LSTM(32))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))  # Add dropout regularization\n",
    "model.add(Dense(len(np.unique(labels)), activation='softmax'))\n",
    "\n",
    "\n",
    "# adam optmizer with custom learning rate\n",
    "opt= optimizers.Adam(0.01)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hX-v7sgwzvGb",
    "outputId": "af2e11e7-448d-49f9-e937-8864de290d3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 23s 128ms/step - loss: 2.3357 - accuracy: 0.3663\n",
      "Test Loss: 2.3356997966766357\n",
      "Test Accuracy: 0.3662608563899994\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdUaEJwsEvqN"
   },
   "source": [
    "## 5. Share insights on relative performance comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnHb8foLE6KX"
   },
   "source": [
    "\n",
    "### A. Which vectorizer performed better? Probable reason?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Okg5SIQtTAMH"
   },
   "source": [
    "*Count Vectorizer is performed better than TF-IDF Vectorizer*\n",
    "\n",
    "Probable reasons are below,\n",
    "\n",
    "**1. Task Requirements:** CountVectorizer may have been more suitable for the task's requirements. Depending on the nature of the classification problem, word frequency and occurrence might play a crucial role in determining the labels or topics. CountVectorizer directly captures this information, making it a better choice if the task primarily relies on word counts rather than the rarity of terms.\n",
    "\n",
    "**2. Word Importance:** In certain scenarios, the importance of words may be better reflected by their frequency rather than their rarity. For instance, if your classification task involves identifying specific topics or distinguishing certain patterns based on common words, CountVectorizer's emphasis on frequency can capture those patterns effectively.\n",
    "\n",
    "**3. Domain-Specific Considerations:** The nature of your specific domain or dataset may favor CountVectorizer. For example, if your dataset consists of informal texts such as social media posts or blogs where specific words or phrases are strongly associated with the target labels, CountVectorizer's focus on word frequency might align better with the underlying patterns in the data.\n",
    "\n",
    "**4. Document Length:** CountVectorizer does not consider document length normalization, while TF-IDF accounts for term frequency relative to document length. If longer documents in your dataset contain more informative content or exhibit stronger patterns, CountVectorizer's representation of raw word counts might capture that signal better than TF-IDF's normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Xe7cBWnE666"
   },
   "source": [
    "\n",
    "### B. Which model outperformed? Probable reason? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhOqiBRcWEt_"
   },
   "source": [
    "*Support Vector Classfier Model outperformed.*\n",
    "\n",
    "Probable reasons are below,\n",
    "\n",
    "**1. Handling complex decision boundaries:** SVC is known for its ability to handle complex decision boundaries due to its kernel trick, which can transform the input data into a higher-dimensional feature space. This can be advantageous when the data points are not linearly separable. RF and NB models, on the other hand, are based on ensemble methods and may struggle with capturing complex relationships.\n",
    "\n",
    "**2. Robustness to noise:** SVC can be robust to noisy data because it aims to find a decision boundary with the maximum margin of separation between classes. This property helps in reducing the influence of noisy or outlier data points. In contrast, RF models can be sensitive to noise since they construct decision trees based on impurity measures.\n",
    "\n",
    "**3. Limited training data:** SVC can perform well with limited training data, especially when combined with appropriate kernel functions. This is particularly useful in scenarios where the dataset is small, and the other models may suffer from overfitting. RF and LSTM models, in particular, might require more data to generalize effectively.\n",
    "\n",
    "**4. Class imbalance:** If the dataset is imbalanced, meaning some classes have significantly fewer samples than others, SVC can handle this situation well. It uses a weighted approach or cost-sensitive learning to give more importance to the minority class. RF and NB models may struggle with imbalanced data if not explicitly addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sU1A22AeE8Tx"
   },
   "source": [
    "### C. Which parameter/hyperparameter significantly helped to improve performance?Probable reason?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAf_bwsSZxbl"
   },
   "source": [
    "The hyperparmeter of Random Forest \"Number of Trees\" & \"Maximum Depth\" are significantly helped to improve performancce.\n",
    "\n",
    "Probable reasons are below,\n",
    "\n",
    "**1. Number of Trees (Random Forest):** In Random Forest, the number of trees in the ensemble is a critical hyperparameter. Increasing the number of trees can improve performance up to a certain point, as it allows for more robust and accurate predictions by reducing overfitting. However, setting the number of trees too high can lead to increased computational complexity without significant gains in performance.\n",
    "\n",
    "**2. Maximum Depth (Decision Trees):** For models that use decision trees, such as Random Forest or Gradient Boosting, the maximum depth of each tree is an important parameter. A deeper tree can capture more complex relationships in the data but may also increase the risk of overfitting. Finding the right balance between capturing sufficient complexity and preventing overfitting is crucial for optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVCGMRWrE81V"
   },
   "source": [
    "### D. According to you, which performance metric should be given most importance, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi05vZ26ajr5"
   },
   "source": [
    "*According to me, **F1-Score** should be given most importance.*\n",
    "\n",
    "And the reasons are below,\n",
    "\n",
    "**1. Balanced measure:** The F1 score provides a balanced measure of a model's performance by considering both precision and recall. It takes into account both the ability to correctly predict positive instances (precision) and the ability to identify all positive instances (recall). By combining these two metrics into a single score, the F1 score provides a comprehensive evaluation of the model's performance.\n",
    "\n",
    "**2. Suitable for imbalanced datasets:** The F1 score is particularly useful when dealing with imbalanced datasets, where one class has a significantly larger number of instances than the other. In such cases, accuracy may be misleading, as a model can achieve high accuracy by simply predicting the majority class most of the time. The F1 score takes into account the performance on both positive and negative instances, providing a more accurate assessment of the model's effectiveness in handling imbalanced class distributions.\n",
    "\n",
    "**3. Emphasis on errors:** The F1 score places equal importance on false positives and false negatives. This is important when the costs or consequences of these errors differ. For example, in spam email detection, it may be more critical to minimize false negatives (classifying spam as non-spam) to avoid missing important messages, even if it means tolerating a higher rate of false positives (classifying non-spam as spam). The F1 score allows you to evaluate the model's performance while considering the specific context and priorities of the problem.\n",
    "\n",
    "**4. Single scalar value:** The F1 score condenses precision and recall into a single scalar value, making it easy to compare and rank different models. It simplifies the evaluation process by providing a unified measure of performance, allowing for straightforward comparisons and decision-making."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
