{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5UnMe3Ym9sU"
   },
   "source": [
    "# COMPUTER VISON PROJECT - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZworHNXrRuD"
   },
   "source": [
    "## Author: Sridharan Chandran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_Cood_0rTrE"
   },
   "source": [
    "## Part - B\n",
    "**• DOMAIN:** Entertainment\n",
    "\n",
    "**• CONTEXT:** Company X owns a movie application and repository which caters movie streaming to millions of users who on subscription\n",
    "basis. Company wants to automate the process of cast and crew information in each scene from a movie such that when a user pauses on\n",
    "the movie and clicks on cast information button, the app will show details of the actor in the scene. Company has an in-house computer\n",
    "vision and multimedia experts who need to detect faces from screen shots from the movie scene.\n",
    "The data labelling is already done. Since there higher time complexity is involved in the\n",
    "\n",
    "**• DATA DESCRIPTION:** The dataset comprises of face images.\n",
    "\n",
    "**• PROJECT OBJECTIVE:** To create an image dataset to be used by AI team build an image classifier data. Profile images of people are given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwsI8Fq1rUBV"
   },
   "source": [
    "## Steps and tasks:\n",
    "### 1. Read/import images from folder ‘training_images’.\n",
    "### 2. Write a loop which will iterate through all the images in the ‘training_images’ folder and detect the faces present on all the images. \n",
    "Hint: You can use ’haarcascade_frontalface_default.xml’ from internet to detect faces which is available open source.\n",
    "### 3. From the same loop above, extract metadata of the faces and write into a DataFrame.\n",
    "### 4. Save the output Dataframe in .csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ygrgp9jirUIL"
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import Dense,Dropout,Flatten,Conv2D, MaxPooling2D, MaxPool2D, GlobalMaxPooling2D, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc,classification_report, roc_curve\n",
    "from tensorflow.keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras import backend\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from glob import glob\n",
    "import cv2\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "vy3DJabnrUNn",
    "outputId": "2e8c3790-ecd9-464e-a323-2ef8baac2494"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6VdwYm0rUdP",
    "outputId": "98e5c100-acc7-4319-ac4e-cd1c3eeb7d06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RxlhUZ2KrUmc"
   },
   "outputs": [],
   "source": [
    "# Extract the ZIP file\n",
    "file_path = \"/content/drive/My Drive/Colab Notebooks/My Python Projects/CV Project - 2 - Face Recognition/training_images.zip\"\n",
    "\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(file_path,'r') as zip:\n",
    "  zip.extractall(path='/content/drive/My Drive/Colab Notebooks/My Python Projects/CV Project - 2 - Face Recognition/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4plykKNLrVQ3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Images path\n",
    "path = '/content/drive/My Drive/Colab Notebooks/My Python Projects/CV Project - 2 - Face Recognition/training_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-HX04RESrWDc"
   },
   "outputs": [],
   "source": [
    "# Read the images from the folder\n",
    "images = []\n",
    "for filename in os.listdir(path):\n",
    "    img = cv2.imread(os.path.join(path, filename))\n",
    "    if img is not None:\n",
    "        images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qRvvfaSU0vYU"
   },
   "outputs": [],
   "source": [
    "# Load the Cascade_frontalface_default file\n",
    "face_cascade = cv2.CascadeClassifier('/content/drive/My Drive/Colab Notebooks/My Python Projects/CV Project - 2 - Face Recognition//haarcascade_frontalface_default.xml')\n",
    "\n",
    "face_data = []\n",
    "\n",
    "for img in images:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "      # Append the face data to the list\n",
    "    for (x,y,w,h) in faces:\n",
    "        face_data.append([x, y, w, h, len(faces), filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "v33SUbewNvc8"
   },
   "outputs": [],
   "source": [
    "# Save metadata of the images to dataframe\n",
    "\n",
    "df = pd.DataFrame(face_data, columns=[\"x\", \"y\", \"w\", \"h\", \"Total_faces\", \"Image_Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "V6SaA49xD_v0",
    "outputId": "7fb4d2d8-5a88-4426-d6e2-ff7e310dec0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e7ab419a-b020-488a-99ac-65f5e663d096\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>Total_faces</th>\n",
       "      <th>Image_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>149</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>1</td>\n",
       "      <td>real_00720.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269</td>\n",
       "      <td>260</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>real_00720.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>43</td>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>1</td>\n",
       "      <td>real_00720.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>402</td>\n",
       "      <td>18</td>\n",
       "      <td>138</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>real_00720.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99</td>\n",
       "      <td>170</td>\n",
       "      <td>387</td>\n",
       "      <td>387</td>\n",
       "      <td>1</td>\n",
       "      <td>real_00720.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7ab419a-b020-488a-99ac-65f5e663d096')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e7ab419a-b020-488a-99ac-65f5e663d096 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e7ab419a-b020-488a-99ac-65f5e663d096');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     x    y    w    h  Total_faces      Image_Name\n",
       "0   73  149  398  398            1  real_00720.jpg\n",
       "1  269  260   76   76            1  real_00720.jpg\n",
       "2   65   43  491  491            1  real_00720.jpg\n",
       "3  402   18  138  138            1  real_00720.jpg\n",
       "4   99  170  387  387            1  real_00720.jpg"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NvApLclCKL45"
   },
   "outputs": [],
   "source": [
    "# Dataframe to csv file\n",
    "\n",
    "df.to_csv('/content/drive/My Drive/Colab Notebooks/My Python Projects/CV Project - 2 - Face Recognition/face_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
